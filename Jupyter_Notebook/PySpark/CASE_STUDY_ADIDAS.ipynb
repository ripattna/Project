{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b514db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "\n",
    "# Creating the SparkSession\n",
    "spark = SparkSession.builder.appName('Case_Study_Adidas').master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af131e98",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45d78820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON file into dataframe\n",
    "path = 'C:\\\\BigData\\\\ol_cdump.json'\n",
    "data_df = spark.read.option(\"multiline\", \"false\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").json(path)\n",
    "\n",
    "# print(type(df))\n",
    "# Printing the Schema\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44cc30d",
   "metadata": {},
   "source": [
    "# 2. Make sure your data set is cleaned enough, so we for example don't include in results with empty/null \"titles\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0231c0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------+------------+\n",
      "|title                                                          |publish_date|\n",
      "+---------------------------------------------------------------+------------+\n",
      "|New directions for federal housing policy                      |1977        |\n",
      "|Fine-line developer                                            |1975        |\n",
      "|Effective listening and cognitive learning at the college level|1966        |\n",
      "|A child's first total communication book                       |1974        |\n",
      "|State employment opportunities for anthropologists             |1974        |\n",
      "|Paintings by American masters                                  |1966        |\n",
      "|The tale of the wee old woman                                  |1930        |\n",
      "|Regents examinations in New York State after 100 years         |1965        |\n",
      "|Picture books for creative thinking, a bibliography            |1974        |\n",
      "|The exemption of minors from attendance                        |1971        |\n",
      "+---------------------------------------------------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering the data\n",
    "\n",
    "df = data_df.filter(data_df.title.isNotNull()).filter(data_df.number_of_pages <'20').filter(data_df.publish_date <= '1990')\n",
    "\n",
    "df.select(\"title\",\"publish_date\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter((col(\"act_date\") >= \"2016-10-01\") & (col(\"act_date\") <= \"2017-04-01\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e1443",
   "metadata": {},
   "source": [
    "# 3.1 Select all \"Harry Potter\" books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af06cfe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+-------------+\n",
      "|title                                   |publish_date |\n",
      "+----------------------------------------+-------------+\n",
      "|Harry Potter and the philosopher's stone|1998         |\n",
      "|Harry Potter y la piedra filosofal      |2000         |\n",
      "|The Science of Harry Potter             |June 23, 2003|\n",
      "+----------------------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select all \"Harry Potter\" books\n",
    "\n",
    "df.filter(col(\"title\").contains(\"Harry Potter\")).select(\"title\",\"publish_date\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc36de9",
   "metadata": {},
   "source": [
    "# 3.2 Get the book with the most pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06536044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------+------------+\n",
      "|number_of_pages|title                        |publish_date|\n",
      "+---------------+-----------------------------+------------+\n",
      "|48418          |Nihon shokuminchi kenchikuron|2008        |\n",
      "+---------------+-----------------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To Get the book with the most pages\n",
    "\n",
    "df.createOrReplaceTempView(\"records\")\n",
    "spark.sql(\"select number_of_pages,title,publish_date from(select *, dense_rank() over(order by number_of_pages desc)r from records) where r=1\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5282a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48418"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To Get the book with the most pages(No of Pages)\n",
    "\n",
    "df.groupby().max('number_of_pages').collect()[0].asDict()['max(number_of_pages)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076bbfa",
   "metadata": {},
   "source": [
    "# 3.3 Find the Top 5 authors with most written books (assuming author in first position in the array, \"key\" field and each row is a different book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b2a7246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|authors                            |\n",
      "+-----------------------------------+\n",
      "|[{null, /authors/OL5510271A, null}]|\n",
      "|[{null, /authors/OL4442921A, null}]|\n",
      "|[{null, /authors/OL607566A, null}] |\n",
      "|[{null, /authors/OL130993A, null}] |\n",
      "|[{null, /authors/OL726653A, null}] |\n",
      "+-----------------------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Find the Top 5 authors with most written books \n",
    "# (assuming author in first position in the array, \"key\" field and each row is a different book)\n",
    "\n",
    "sql_df = spark.sql(\"select authors from(select *, dense_rank() over(order by number_of_pages desc)r from records) where r between 1 and 5\")\n",
    "\n",
    "print(sql_df.show(5, truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a8078",
   "metadata": {},
   "source": [
    "# 3.4 Find the Top 5 genres with most books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e5f22b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|genres                  |\n",
      "+------------------------+\n",
      "|[Early works to 1800]   |\n",
      "|[Outlines, syllabi, etc]|\n",
      "|[Bibliography]          |\n",
      "+------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Find the Top 5 genres with most books\n",
    "\n",
    "df_geners = df.filter(data_df.genres.isNotNull())\n",
    "\n",
    "df_geners.select(\"genres\").show(3, truncate=False)\n",
    "print(type(df_geners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6cef90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[alternate_names: array<string>, authors: array<struct<author:struct<key:string>,key:string,type:string>>, bio: string, birth_date: string, by_statement: string, contributions: array<string>, contributors: array<struct<name:string,role:string>>, copyright_date: string, covers: array<bigint>, created: struct<type:string,value:string>, death_date: string, description: string, dewey_decimal_class: array<string>, dewey_number: array<string>, download_url: array<string>, edition_name: string, excerpts: array<struct<excerpt:struct<type:string,value:string>,page:string>>, first_publish_date: string, first_sentence: string, full_title: string, fuller_name: string, genres: array<string>, ia_box_id: array<string>, ia_loaded_id: string, identifiers: struct<amazon:array<string>,amazon.co.uk_asin:array<string>,goodreads:array<string>,librarything:array<string>>, isbn_10: array<string>, isbn_13: array<string>, isbn_invalid: array<string>, isbn_odd_length: array<string>, key: string, languages: array<struct<key:string>>, last_modified: struct<type:string,value:string>, latest_revision: bigint, lc_classifications: array<string>, lccn: array<string>, links: array<struct<title:string,type:struct<key:string>,url:string>>, location: string, name: string, notes: string, number_of_pages: bigint, ocaid: string, oclc_number: array<string>, oclc_numbers: array<string>, other_titles: array<string>, pagination: string, personal_name: string, photos: array<bigint>, physical_dimensions: string, physical_format: string, publish_country: string, publish_date: string, publish_places: array<string>, publishers: array<string>, purchase_url: array<string>, revision: bigint, series: array<string>, source_records: array<string>, subject_people: array<string>, subject_place: array<string>, subject_places: array<string>, subject_time: array<string>, subject_times: array<string>, subjects: array<string>, subtitle: string, table_of_contents: array<struct<class:string,label:string,level:bigint,pagenum:string,title:string,type:string,value:string>>, title: string, title_prefix: string, type: struct<key:string>, uri_descriptions: array<string>, uris: array<string>, url: array<string>, website: string, weight: string, work_title: array<string>, work_titles: array<string>, works: array<struct<key:string>>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geners.createOrReplaceTempView(\"Sample1\")\n",
    "spark.sql(\"select * from sample1 limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_geners.groupby().max('genres').collect()[0].asDict()['max(genres)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc53fc10",
   "metadata": {},
   "source": [
    "# 3.5 Get the avg. number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59938f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the avg. number of pages\n",
    "df.groupby().avg('number_of_pages').collect()[0].asDict()['avg(number_of_pages)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per publish year, get the number of authors that published at least one book\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
