{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968933df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession,Row\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import broadcast\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import sum, desc, max, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f489883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Case-Study_2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba90e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Csv file\n",
    "\n",
    "fact = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"C:\\\\BigData\\\\use-case-data-processing-main\\\\fact.csv\")\n",
    "lookup = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"C:\\\\BigData\\\\use-case-data-processing-main\\\\lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f942e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = fact.join(broadcast(lookup), 'WEB_PAGEID', 'inner')\\\n",
    "    .select(fact.USER_ID,fact.VIEW_TIME,fact.WEB_PAGEID,lookup.WEBPAGE_TYPE)\\\n",
    "    .withColumn(\"DATE_OF_REFERENCE\", to_date(lit('12-10-2019'),'dd-MM-yyyy'))\\\n",
    "    .withColumn('VIEW_TIME', to_date(unix_timestamp(col('VIEW_TIME'), 'dd/MM/yyyy HH:mm').cast(\"timestamp\")))\\\n",
    "    .withColumn(\"diff\", expr(\"datediff(DATE_OF_REFERENCE, VIEW_TIME)\"))\n",
    "\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"pageview_news_fre_365\", when((upper(df['WEBPAGE_TYPE']) == \"NEWS\") \n",
    "                                                 & (df['diff'] <= \"365\"), 1).otherwise(0)) \\\n",
    "       .withColumn(\"pageview_news_fre_730\", when((upper(df['WEBPAGE_TYPE']) == \"NEWS\") \n",
    "                                                 & (df.diff.between(\"365\", \"730\")), 1).otherwise(0)) \\\n",
    "       .withColumn(\"pageview_news_fre_1460\", when((upper(df['WEBPAGE_TYPE']) == \"NEWS\") \n",
    "                                                  & (df.diff.between(\"730\", \"1460\")), 1).otherwise(0)) \\\n",
    "       .withColumn(\"pageview_news_fre_2920\", when((upper(df['WEBPAGE_TYPE']) == \"NEWS\") \n",
    "                                                  & (df.diff.between(\"1460\", \"2920\")), 1).otherwise(0)) \\\n",
    "       .withColumn(\"pageview_movies_fre_365\", when((upper(df['WEBPAGE_TYPE']) == \"MOVIES\") \n",
    "                                                   & (df['diff'] <= \"365\"), 1).otherwise(0)) \\\n",
    "       .withColumn(\"pageview_movies_fre_730\", when((upper(df['WEBPAGE_TYPE']) == \"MOVIES\")\n",
    "                                                   & (df.diff.between(\"365\", \"730\")), 1).otherwise(0)) \\\n",
    "       .withColumn(\"pageview_movies_fre_1460\", when((upper(df['WEBPAGE_TYPE']) == \"MOVIES\") \n",
    "                                                    & (df.diff.between(\"730\", \"1460\")), 1).otherwise(0)) \\\n",
    "       .withColumn(\"pageview_movies_fre_2920\", when((upper(df['WEBPAGE_TYPE']) == \"MOVIES\") \n",
    "                                                    & (df.diff.between(\"1460\", \"2920\")), 1).otherwise(0))\n",
    "df.limit(4).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import sum, desc, max, min\n",
    "\n",
    "exprs = [sum(x).alias(x) for x in\n",
    "         ['pageview_news_fre_365', 'pageview_news_fre_730', 'pageview_news_fre_1460', 'pageview_news_fre_2920',\n",
    "          'pageview_movies_fre_365', 'pageview_movies_fre_730', 'pageview_movies_fre_1460', 'pageview_movies_fre_2920']]\n",
    "\n",
    "exprs.append(max('diff').alias('recency_view_time'))\n",
    "exprs.append(count('diff').alias('frequency_view_time'))\n",
    "df.groupBy(\"USER_ID\").agg(*exprs).toPandas().head(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
